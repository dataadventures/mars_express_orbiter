{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import trange, tqdm\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (5, 5)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from hackathon.utils.utils import *\n",
    "from hackathon.utils.draw_utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = parse_data(\"../data/test_data.csv\")\n",
    "train_data = parse_data(\"../data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting train_data into train / validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You should test how your model performs on data that was not seen during training\n",
    "### It was the \"first rule of proper machine learning\"\n",
    "### Purpose of validation data is choosing best model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37928, 59), (17447, 59))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dates = train_data.index < '2013-01-01 00:00:00'\n",
    "\n",
    "train_df = train_data[train_dates]\n",
    "valid_df = train_data[~train_dates]\n",
    "\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract X and y for train/valid/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunmars_km', 'earthmars_km', 'sunmarsearthangle_deg', 'solarconstantmars', 'eclipseduration_min', 'occultationduration_min', 'sa', 'sx', 'sy', 'sz', 'dmop_count_24h_AAAA', 'dmop_count_24h_AACF', 'dmop_count_24h_ADMC', 'dmop_count_24h_AHHH', 'dmop_count_24h_AMMM', 'dmop_count_24h_AOOO', 'dmop_count_24h_APSF', 'dmop_count_24h_APWF', 'dmop_count_24h_ASEQ', 'dmop_count_24h_ASSS', 'dmop_count_24h_ASXX', 'dmop_count_24h_ATMB', 'dmop_count_24h_ATTT', 'dmop_count_24h_AVVV', 'dmop_count_24h_AXXX', 'dmop_count_24h_sum']\n",
      "\n",
      "['NPWD2372', 'NPWD2401', 'NPWD2402', 'NPWD2451', 'NPWD2471', 'NPWD2472', 'NPWD2481', 'NPWD2482', 'NPWD2491', 'NPWD2501', 'NPWD2531', 'NPWD2532', 'NPWD2551', 'NPWD2552', 'NPWD2561', 'NPWD2562', 'NPWD2691', 'NPWD2692', 'NPWD2721', 'NPWD2722', 'NPWD2742', 'NPWD2771', 'NPWD2791', 'NPWD2792', 'NPWD2801', 'NPWD2802', 'NPWD2821', 'NPWD2851', 'NPWD2852', 'NPWD2871', 'NPWD2872', 'NPWD2881', 'NPWD2882']\n"
     ]
    }
   ],
   "source": [
    "x_columns = filter(lambda x: \"NPWD\" not in x and 'ut_ms' not in x, train_df.columns)\n",
    "print(x_columns)\n",
    "print()\n",
    "y_columns = filter(lambda x: \"NPWD\"  in x, train_df.columns)\n",
    "print(y_columns)\n",
    "\n",
    "# create train/valid datasets\n",
    "X_train = train_df[x_columns]\n",
    "y_train = train_df[y_columns]\n",
    "\n",
    "X_valid = valid_df[x_columns]\n",
    "y_valid = valid_df[y_columns]\n",
    "\n",
    "X_test = test_data[x_columns]\n",
    "y_test = test_data[y_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a simple linear model (linear regression) on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your score on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are checking how the model performs on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11585583530285432"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hackathon.utils.utils import RMSE\n",
    "RMSE(model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a maybe-better-model (tree ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maybe_better_linear_model = ElasticNet()\n",
    "maybe_better_linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11685221210036432"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(maybe_better_linear_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It was worse :<< so sad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the better performing model on (train + valid) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LinearRegression()\n",
    "X_train_valid = pd.concat([X_train, X_valid])\n",
    "y_train_valid = pd.concat([y_train, y_valid])\n",
    "best_model.fit(X_train_valid, y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission file which you will upload later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_df(model, X_test_features, y_columns): \n",
    "    X_test = X_test_features\n",
    "    y_test_pred = model.predict(X_test_features)\n",
    "    submision_df = pd.DataFrame(data=y_test_pred, index=X_test.index, columns=y_columns)\n",
    "    submision_df.index = to_utms(submision_df.index)\n",
    "    return submision_df\n",
    "\n",
    "\n",
    "sub_df = create_submission_df(best_model, X_test[x_columns], y_columns)\n",
    "sub_df.to_csv(\"../submissions/my_first_model_prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs231n]",
   "language": "python",
   "name": "conda-env-cs231n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
